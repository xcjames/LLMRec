/home/users/ntu/chen035/.conda/envs/LC-Rec/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:13<00:13, 13.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  8.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.47s/it]
Traceback (most recent call last):
  File "/home/users/ntu/chen035/.conda/envs/LC-Rec/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1364, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/users/ntu/chen035/.conda/envs/LC-Rec/lib/python3.11/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/users/ntu/chen035/.conda/envs/LC-Rec/lib/python3.11/site-packages/transformers/trainer.py", line 190, in <module>
    from peft import PeftModel
  File "/home/users/ntu/chen035/.conda/envs/LC-Rec/lib/python3.11/site-packages/peft/__init__.py", line 22, in <module>
    from .auto import (
  File "/home/users/ntu/chen035/.conda/envs/LC-Rec/lib/python3.11/site-packages/peft/auto.py", line 32, in <module>
    from .mapping import MODEL_TYPE_TO_PEFT_MODEL_MAPPING
  File "/home/users/ntu/chen035/.conda/envs/LC-Rec/lib/python3.11/site-packages/peft/mapping.py", line 25, in <module>
    from .mixed_model import PeftMixedModel
  File "/home/users/ntu/chen035/.conda/envs/LC-Rec/lib/python3.11/site-packages/peft/mixed_model.py", line 29, in <module>
    from .peft_model import PeftModel
  File "/home/users/ntu/chen035/.conda/envs/LC-Rec/lib/python3.11/site-packages/peft/peft_model.py", line 37, in <module>
    from transformers import Cache, DynamicCache, EncoderDecoderCache, PreTrainedModel
ImportError: cannot import name 'EncoderDecoderCache' from 'transformers' (/home/users/ntu/chen035/.conda/envs/LC-Rec/lib/python3.11/site-packages/transformers/__init__.py)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/scratch/users/ntu/chen035/LC-Rec/finetune.py", line 122, in <module>
    train(args)
  File "/scratch/users/ntu/chen035/LC-Rec/finetune.py", line 67, in train
    trainer = transformers.Trainer(
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/users/ntu/chen035/.conda/envs/LC-Rec/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1354, in __getattr__
    module = self._get_module(self._class_to_module[name])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/users/ntu/chen035/.conda/envs/LC-Rec/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1366, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.trainer because of the following error (look up to see its traceback):
cannot import name 'EncoderDecoderCache' from 'transformers' (/home/users/ntu/chen035/.conda/envs/LC-Rec/lib/python3.11/site-packages/transformers/__init__.py)
E0227 20:19:42.094000 2439026 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 2441409) of binary: /home/users/ntu/chen035/.conda/envs/LC-Rec/bin/python3.11
Traceback (most recent call last):
  File "/home/users/ntu/chen035/.conda/envs/LC-Rec/bin/torchrun", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/users/ntu/chen035/.conda/envs/LC-Rec/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/users/ntu/chen035/.conda/envs/LC-Rec/lib/python3.11/site-packages/torch/distributed/run.py", line 918, in main
    run(args)
  File "/home/users/ntu/chen035/.conda/envs/LC-Rec/lib/python3.11/site-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/home/users/ntu/chen035/.conda/envs/LC-Rec/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/users/ntu/chen035/.conda/envs/LC-Rec/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
finetune.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-02-27_20:19:42
  host      : x1001c0s0b0n1.hostmgmt2001.cm.asp2a.nscc.sg
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 2441409)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
